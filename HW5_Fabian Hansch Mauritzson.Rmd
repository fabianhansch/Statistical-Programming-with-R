---
title: 'SDGB-7844: Homework #5 - Hypothesis Testing & Confidence Intervals'
author: "Fabian Hansch Mauritzson"
date: "December 16, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Two-Sample Hypothesis Test for Proportions

An online men's clothing retailer has developed a testing framework for video advertising on YouTube in order to test the effectiveness of the ads on influencing individuals to purchase from their website.

Over the course of 30 days, 600,000 consumers were reached on YouTube.  Half of the individuals reached with ads on YouTube were served Public Service Announcement ads, while the other half were served ads for the retailer.  

Incrementality testing, also referred to as “Uplift Modeling” or “Incremental Sales Lift”, is a test that measures the impact of a single variable on an individual’s behavior. For digital display or video marketing, it is most commonly used to measure the impact of a branded digital ad (Test Group) against a Public Service Announcement (PSA) ad (Control Group). The lift is measured as the percent difference between the two.

Incremental lift indicates the impact of a particular (digital) advertising tactic on sales – the holy grail of advertising. It is possible to calculate but incremental testing is expensive (budget must still be spent on PSA placebo ads) and subject to many pitfalls unless executed carefully.  For the purposes of this assignment we will assume that all individuals were not exposed to any other advertising for the retailer during the 30 day testing period.

The goal of our test is to determine whether the conversion rate of the test group is different than the conversion rate of our control group.  Conversion rate in this case is defined as $$\textrm{Conversion Rate} = \Bigg(\frac{ \textrm{Individuals in Group Who Purchased}}{\textrm{Total Individuals in Group}}\Bigg)$$

Our hypothesis will test whether the difference in conversion rate or proportion for the test group and control group is statistically significant when $\alpha$ = 0.01.$$H_0 : p_{test} - p_{control} = 0$$ $$H_a : p_{test} - p_{control} \neq 0$$

The data we will be using for the following exercises is __test_control.csv__.  This data represents a simple random sample of 15,000 individuals served PSA ads and 15,000 individuals served a branded digital video ads.  The data also contains an indicator for whether an individual purchased from our retailer after viewing the ad.

1. What variables are available in our data set?  List out the column names and describe the data type of each variable.
user_id, nominal
exposed, binary
gender, binary
age, categorical
income, categorical
purchased, binary


2. How are our test and control samples defined in our data set?

In the column exposed, they have either value Test Group or Control Group. Since exposed can only have two differnt values, this column is binary and the values can be changed to 0 and 1 for later calculations.


3. What proportion of individuals from the test group purchased on the retailer's website after viewing an ad?  What proportion of individuals from the control group purchased on the retailer's website after viewing an ad?

```{r}
#importing libraries
library(tidyverse)
library(dplyr)
library(ggplot2)
#reading in the data
input_data <- read_csv("test_control.csv")

#divide into the two groups
input_data_test <- input_data %>% dplyr::filter(exposed == "Test Group (Exposed)")
input_data_control <- input_data %>% dplyr::filter(exposed == "Control Group (PSA)")

#calculating proportion
count_test <- input_data_test %>% dplyr::filter(purchased == 1)
proportion_test <- nrow(count_test) / nrow(input_data_test)

count_control <- input_data_control %>% dplyr::filter(purchased == 1)
proportion_control <- nrow(count_control) / nrow(input_data_control)

#display result
paste("Test Group: ", proportion_test)
paste("Control Group: ", proportion_control)
```


4. For each of the variables [$gender$, $age$, $income$] create a bar plot to explore the distribution of demographic information in our samples. 

```{r}
gender_counts <- table(input_data$gender)
barplot(gender_counts, main = "Gender Distribution", ylab = "Amount of Observations")

```

```{r}
age_counts <- table(input_data$age)
barplot(age_counts, main = "Age Distribution", ylab = "Amount of Observations")

```

```{r}
par(mar=c(10.1, 4.1, 4.1, 2.1))
income_counts <- table(input_data$income)

#ggplot(data = income_counts, aes(x=input_data.income)) + geom_bar() + scale_x_discrete(guide = guide_axis(n.dodge=2))

barplot(income_counts, main = "Income Distribution", ylab = "Amount of Observations", las = 3)

```


5.  Create a figure with two bar plots (one for the test group and one for the control group) for $age$.  Describe the difference in the distribution between the test and control groups. Compare the percentage of each category between our test and control groups.


The age distribution for the Test Group is very normally distributed while the Control Group is skewed heavily to the right. This can be seen in that the Control Group has over 20% of the respondents between 18-25 years old, while the Test Group only has around 10%.
```{r}
par(mfrow=c(1,2), mar=c(10.1, 4.1, 4.1, 2.1))
test_age_counts <- table(input_data_test$age)
barplot(test_age_counts, main = "Age Test Group", ylab = "Amount of Observations", las = 3)

control_age_counts <- table(input_data_control$age)
barplot(control_age_counts, main = "Age Control Group", ylab = "Amount of Observations", las = 3)

test_prop <- test_age_counts/sum(test_age_counts)
control_prop <- control_age_counts/sum(control_age_counts)

print("Test Proportions")
test_prop
print("Control Proportions")
control_prop

```


6.  Create a figure with two bar plots (one for the test group and one for the control group) for $gender$.  Describe the difference in the distribution between the test and control groups. Add the percentage of each category to your plots.  Why might this variable be important to our analysis?

There is no significant difference in the distribution between the Test Group and Control Group. A difference would impact since men and women have different behavior, which could have impacted the results if not taken into consideration.

```{r}
par(mfrow=c(1,2))
test_gender_counts <- table(input_data_test$gender)
test_gender_prop <- test_gender_counts/sum(test_gender_counts)
barplot(test_gender_counts, main = "Gender Test Group", ylab = "Amount of Observations")
text(x=1.87, y=5000, label=paste(round(test_gender_prop["Male"], digits = 3)))
text(x=0.65, y=5000, label=paste(round(test_gender_prop["Female"], digits = 3)))

control_gender_counts <- table(input_data_control$gender)
control_gender_prop <- control_gender_counts/sum(control_gender_counts)
barplot(control_gender_counts, main = "Gender Test Group", ylab = "Amount of Observations")
text(x=1.87, y=5000, label=paste(round(control_gender_prop["Male"], digits = 3)))
text(x=0.65, y=5000, label=paste(round(control_gender_prop["Female"], digits = 3)))
```


7.  Create a figure with two bar plots (one for the test group and one for the control group) for $income$.  Describe the difference in the distribution between the test and control groups. Compare the percentage of each category between our test and control groups.

These distributions are closer to eachother than age, but further away than gender. The Test Group is skewed slightly left while the control group is skewed slightly right.
```{r}
par(mfrow=c(1,2), mar=c(10.1, 4.1, 4.1, 2.1))
test_income_counts <- table(input_data_test$income)
barplot(test_income_counts, main = "Income Test Group", ylab = "Amount of Observations", las = 3)
(bottom = 10)
control_income_counts <- table(input_data_control$income)
barplot(control_income_counts, main = "Income Control Group", ylab = "Amount of Observations", las = 3)


test_prop_income <- test_income_counts/sum(test_income_counts)
control_prop_income <- control_income_counts/sum(control_income_counts)

print("Test Proportions")
test_prop_income
print("Control Proportions")
control_prop_income
```


8.  How might the differences in the distributions of the categorical variables analyzed in #5 - #7 impact our analysis?  Is it possible that our two samples may represent different types of shoppers?

Since there are some major differences in Age distribution between the two groups, it is defenitely possible that the behavior of the shoppers differ between the groups as well. This might have an impact on the analysis. I would assume that young people are less likely to press on ads being showed to them since they are seeing it so often while older people might see it a different way.

#### Hypothesis Test

9.  What is the difference in the conversion rate for the test and control groups?

There is a 0.4% difference in conversion rate between the Test Group and the Control Group.
```{r}
print(paste("Test Group Conversion Rate: ", proportion_test * 100, "%"))
print(paste("Control Group Conversion Rate: ", proportion_control * 100, "%"))

```


The confidence interval for the difference between two proportions (when n > 30) is defined as $$p_{test} - p_{control} \pm z_{\alpha/2}\sqrt{\frac{p_{test} \times (1-p_{test})}{n_{test}}+  \frac{p_{control} \times (1-p_{control})}{n_{control}} }$$ 

10.  Using the equation above, write a function to calculate the confidence interval for the difference between two proportions.  Your function should include three arguments: p1, p2, n1, n2 and Z.  Your function should return the confidence interval for the difference in two proportions at a given confidence level (in our example, Z = 2.575 when $\alpha$ = 0.01)  Round your results to the first five decimal places.

```{r}
confidence_interval <- function(p1, p2, n1, n2, Z) {
  conf_int_upper <- round((p1 - p2) + (Z * sqrt((p1*(1-p1))/n1 + (p2*(1-p2))/n2)), digits = 5)
  conf_int_lower <- round((p1 - p2) - (Z * sqrt((p1*(1-p1))/n1 + (p2*(1-p2))/n2)), digits = 5)
  
  conf_int <- c(conf_int_lower, conf_int_upper)
  return(conf_int)
  
}

```


11.  Calculate the confidence interval for the difference between the conversion rates for our test and control groups when $\alpha$ = 0.01 (Z = 2.575) using your function.  Does this confidence interval include zero?  What are the implications for the difference between two means when the confidence interval does not include zero?

This confidence interval does not include zero. 
```{r}
conf_int <- confidence_interval(proportion_test, proportion_control, nrow(input_data_test), nrow(input_data_control), 2.575)

print(paste("Lower Limit: ", conf_int[1]))
print(paste("Upper Limit: ", conf_int[2]))
```


12.  Similar to the ```t.test()``` function in R, the ```prop.test()``` function can be used for testing the null hypothesis that the proportions (probabilities of success) in several groups are the same, or that they equal certain given values.  A chi-square test for equality of two proportions is exactly the same test as a z-test (chi-squared distribution with one degree of freedom is just that of a normal deviate, squared). What are the arguments for the function ```prop.test()```?


prop.test() has these arguments: x, n, p, alternative, conf.level, and correct. x, n, and p should all be vectors where x is the data, n is amount of trials, and p is the probability between 0 and 1. alternative specifies if the alternative hypotheses is one- or two-tail. conf.level is simply the confidence level. 
```{r}
#?prop.test
```


13.  Noting that the arguments ```x``` and ```n``` require vectors of values, use the ```prop.test()``` function to test our hypothesis that there is a statistically significant difference between the conversion rates of our test and control groups.  

```{r}
prop_test <- prop.test(x = c(nrow(count_test), nrow(count_control)), n = c(nrow(input_data_test), nrow(input_data_control)), alternative = "two.sided", conf.level = 0.99)

prop_test
```
The confidence intervals for 11 and 13 are not exactly the same. They are differing for me by a slight margin, but I do not know why. Ultimately, the p-value is outside of both intervals so it did not end up mattering for this exercise.



14.  Interpet each output of ```prop.test```.  Explain your p-value in the context of our hypothesis.  Is the difference in the conversion rates for the test and control groups statistically significant?

The p-value is lower than the lower limit of the confidence interval. This means that the null hypothesis is rejected, which means that the conversion rates have a statisticallt significant difference.

15.  Use the function ```pchisq(x, df=1)``` to try to understand the __X-squared__ score value in the output of ```prop.test()```.  What do the "p" functions for distributions calculate in R?  Subtract the value calculated using ```pchisq``` from 1.  What does this value represent?

"p" functions calculate the CDF. 1-pchisq gives the p-value from the prop.test function. 
```{r}
pchisq(11.644, df = 1)

1-pchisq(11.644, df = 1)

```


#### Conclusion

16.  In a few sentences, describe your interpretation of the results we found in this assignment.  How might the demographic data we observed for our test and control groups impact the difference in the two conversion rates?  Do you still believe that the results of our hypothesis test is valid?  Justify your answer.

There is a difference in the conversion rates between the two different groups. Since the Test Group has the higher conversion rate, the claim can be made saying that the ad works. As been discussed earlier, there is a difference in the demographic between the groups which means that there could be some ambiguity to whether this analysis is correct. However, since the significant value was 0.01, the analysis is restriced enough to reduce a lot of the errors, which means that the analysis is still robust enough.
